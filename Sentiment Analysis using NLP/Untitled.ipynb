{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/sumit/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('movie_reviews')\n",
    "import random\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category) \n",
    "            for category in movie_reviews.categories()\n",
    "            for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['the', 'happy', 'bastard', \"'\", 's', 'quick', 'movie', 'review', 'analyze', 'this', 'how', 'does', 'one', 'do', 'a', 'comedy', 'focused', 'on', 'the', 'mob', '?', 'well', ',', 'a', 'few', 'years', 'ago', ',', 'there', 'was', 'a', 'sly', 'little', 'comedy', 'called', 'the', 'freshman', ',', 'which', 'had', 'marlon', 'brando', 'doing', 'a', 'romp', 'of', 'a', 'send', '-', 'up', 'of', 'his', 'famous', 'don', 'corleone', 'character', 'and', ',', 'recently', ',', 'the', 'utterly', 'stupid', '(', 'in', 'a', 'bad', 'way', ')', 'movie', 'mafia', '!', 'failed', 'to', 'really', 'get', 'the', 'joke', '.', 'this', 'time', 'around', ',', 'however', ',', 'warner', 'bros', '.', 'may', 'have', 'gotten', 'it', 'right', 'with', 'analyze', 'this', ',', 'a', 'movie', 'that', 'hits', 'its', 'targets', 'more', 'than', 'it', 'misses', '.', '.', '.', 'and', 'for', 'plenty', 'of', 'reasons', '.', 'the', 'story', 'goes', 'like', 'this', '.', 'a', 'mobster', '(', 'robert', 'deniro', ')', 'finds', 'himself', 'receiving', 'several', 'panic', 'attacks', 'as', 'of', 'late', ',', 'fueled', 'by', 'the', 'stress', 'of', 'an', 'upcoming', 'mobster', 'meeting', 'and', 'a', 'near', '-', 'death', 'following', 'a', 'drive', '-', 'by', 'shooting', '.', 'it', \"'\", 's', 'these', 'attacks', 'that', 'prompt', 'him', 'to', 'hire', 'a', 'psychiatrist', '(', 'billy', 'crystal', ')', 'who', \"'\", 's', 'mostly', 'reluctant', 'to', 'take', 'the', 'mobster', \"'\", 's', 'case', 'for', 'two', 'reasons', '.', 'first', ',', 'of', 'course', ',', 'he', \"'\", 's', 'a', 'mobster', ',', 'but', 'secondly', ',', 'he', \"'\", 's', 'trying', 'to', 'get', 'married', 'and', 'enjoy', 'a', 'quiet', 'honeymoon', 'with', 'his', 'wife', '(', 'lisa', 'kudrow', ')', 'and', 'kid', '.', 'and', ',', 'of', 'course', ',', 'he', 'can', \"'\", 't', 'rest', 'worth', 'for', 'a', 'moment', 'because', 'the', 'mobster', \"'\", 's', 'goons', 'are', 'always', 'needing', 'the', 'shrink', 'for', 'something', ',', 'be', 'it', 'a', 'quick', 'consultation', 'or', 'dream', 'analyzation', '.', 'fortunately', ',', 'the', 'movie', 'is', 'played', 'out', 'for', 'plenty', 'of', 'laughs', '.', 'director', 'harold', 'ramis', '(', 'who', 'also', 'helmed', 'the', 'comedy', 'multiplicity', ',', 'which', 'wasn', \"'\", 't', 'half', 'bad', ')', 'keeps', 'the', 'tone', 'peppy', 'and', 'light', ',', 'even', 'if', 'it', \"'\", 's', 'sometimes', 'sprinkled', 'by', 'slight', 'dramatic', 'moments', '(', 'shootings', 'can', \"'\", 't', 'always', 'be', 'taken', 'for', 'laughs', ',', 'you', 'know', ')', '.', 'deniro', 'does', 'some', 'of', 'his', 'finest', 'comic', 'work', 'since', 'the', 'king', 'of', 'comedy', ',', 'giving', 'off', 'a', 'somewhat', 'similar', 'performance', 'to', 'his', 'role', 'in', 'goodfellas', ',', 'but', 'with', 'a', 'bit', 'of', 'a', 'lighter', 'heart', '.', '(', 'a', 'scene', 'where', 'he', 'tries', 'to', 'display', 'his', 'anger', 'over', 'the', 'phone', 'and', 'fails', 'miserably', 'is', 'hilarious', '.', ')', 'crystal', 'plays', 'an', 'excellent', 'straight', 'man', 'to', 'deniro', \"'\", 's', 'character', ',', 'uplifting', 'him', 'from', 'such', 'bombs', 'as', 'father', \"'\", 's', 'day', 'and', 'my', 'giant', '.', 'kudrow', 'is', 'also', 'a', 'hoot', 'as', 'crystal', \"'\", 's', 'wife', '-', 'to', '-', 'be', ',', 'who', \"'\", 's', 'on', 'the', 'verge', 'of', 'a', 'breakdown', 'thanks', 'to', 'deniro', \"'\", 's', 'presence', '.', 'is', 'the', 'movie', 'perfect', '?', 'not', 'really', ',', 'thanks', 'to', 'a', 'simplistic', 'ending', 'and', 'some', 'slightly', 'wasted', 'moments', 'with', 'a', 'character', 'portrayed', 'by', 'chazz', 'palminteri', '(', 'he', \"'\", 's', 'a', 'comic', 'actor', ',', 'too', ',', 'come', 'on', ',', 'give', 'him', 'some', 'more', '!', ')', ',', 'but', 'it', 'is', 'an', 'enjoyable', 'romp', 'that', 'lets', 'deniro', 'do', 'something', 'different', 'but', 'same', 'for', 'a', 'change', ',', 'taking', 'his', 'dramatic', 'act', 'to', 'a', 'new', 'field', 'of', 'comedy', '.', 'kudos', 'to', 'crystal', 'and', 'kudrow', 'for', 'not', 'just', 'making', 'it', 'his', 'show', ',', 'either', '.', 'line', 'of', 'the', 'movie', ':', 'crystal', ':', '\"', 'when', 'you', 'said', 'you', 'needed', 'family', 'therapy', ',', 'this', 'is', 'not', 'the', 'family', 'i', 'had', 'in', 'mind', '!', '\"'], 'pos')\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(documents)\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 77717), ('the', 76529), ('.', 65876), ('a', 38106), ('and', 35576), ('of', 34123), ('to', 31937), (\"'\", 30585), ('is', 25195), ('in', 21822), ('s', 18513), ('\"', 17612), ('it', 16107), ('that', 15924), ('-', 15595)]\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "    \n",
    "all_words = nltk.FreqDist(all_words)\n",
    "print(all_words.most_common(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = list(all_words.keys())[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No such file or directory: '/home/sumit/nltk_data/corpora/movie_reviews/neg/cv00_29416.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c0a5ba4a7067>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'neg/cv00_29416.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/nltk/corpus/reader/plaintext.py\u001b[0m in \u001b[0;36mwords\u001b[0;34m(self, fileids, categories)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         return PlaintextCorpusReader.words(\n\u001b[0;32m--> 168\u001b[0;31m             self, self._resolve(fileids, categories))\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         return PlaintextCorpusReader.sents(\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/nltk/corpus/reader/plaintext.py\u001b[0m in \u001b[0;36mwords\u001b[0;34m(self, fileids)\u001b[0m\n\u001b[1;32m     87\u001b[0m         return concat([self.CorpusView(path, self._read_word_block, encoding=enc)\n\u001b[1;32m     88\u001b[0m                        \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                        in self.abspaths(fileids, True, True)])\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/nltk/corpus/reader/api.py\u001b[0m in \u001b[0;36mabspaths\u001b[0;34m(self, fileids, include_encoding, include_fileid)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minclude_encoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minclude_fileid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/nltk/corpus/reader/api.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minclude_encoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minclude_fileid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, fileid)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mFileSystemPathPointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/nltk/compat.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_py3_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_decorator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, _path)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No such file or directory: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: No such file or directory: '/home/sumit/nltk_data/corpora/movie_reviews/neg/cv00_29416.txt'"
     ]
    }
   ],
   "source": [
    "print(find_features(movie_reviews.words('neg/cv00_29416.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = featuresets[:1900]\n",
    "\n",
    "testing_set = featuresets[1900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy percent:  68.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier accuracy percent: \", (nltk.classify.accuracy(classifier, testing_set)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 conveys = True              pos : neg    =      8.9 : 1.0\n",
      "                    scum = True              pos : neg    =      7.6 : 1.0\n",
      "                narrates = True              pos : neg    =      7.6 : 1.0\n",
      "                  denial = True              pos : neg    =      7.6 : 1.0\n",
      "                  feeble = True              neg : pos    =      7.1 : 1.0\n",
      "                    lean = True              pos : neg    =      6.9 : 1.0\n",
      "               balancing = True              pos : neg    =      6.9 : 1.0\n",
      "                  regard = True              pos : neg    =      6.9 : 1.0\n",
      "                 cunning = True              pos : neg    =      6.3 : 1.0\n",
      "               hawthorne = True              pos : neg    =      6.3 : 1.0\n",
      "                     dud = True              neg : pos    =      6.3 : 1.0\n",
      "                headache = True              neg : pos    =      6.3 : 1.0\n",
      "                 ordered = True              pos : neg    =      5.7 : 1.0\n",
      "                promptly = True              neg : pos    =      5.7 : 1.0\n",
      "                avengers = True              neg : pos    =      5.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_classifier = open(\"naivebayes.pickle\",\"wb\")\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_f = open(\"naivebayes.pickle\",\"rb\")\n",
    "classifier = pickle.load(classifier_f)\n",
    "classifier_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
